# pytorch_dataparallel_sandbox
How does nn.DistributedDataParallell work? How should I change my learning rate to account for it? This repo may help you try some stuff out.

### Some Experiments
The following experiment was run on an 8-gpu machine.
